{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f963c8ba",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:25.809919Z",
     "iopub.status.busy": "2024-11-18T14:57:25.808579Z",
     "iopub.status.idle": "2024-11-18T14:57:31.029876Z",
     "shell.execute_reply": "2024-11-18T14:57:31.028611Z"
    },
    "papermill": {
     "duration": 5.234214,
     "end_time": "2024-11-18T14:57:31.032917",
     "exception": false,
     "start_time": "2024-11-18T14:57:25.798703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af27286",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:31.048239Z",
     "iopub.status.busy": "2024-11-18T14:57:31.047672Z",
     "iopub.status.idle": "2024-11-18T14:57:36.294779Z",
     "shell.execute_reply": "2024-11-18T14:57:36.293075Z"
    },
    "papermill": {
     "duration": 5.257854,
     "end_time": "2024-11-18T14:57:36.297782",
     "exception": false,
     "start_time": "2024-11-18T14:57:31.039928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 15923247.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 472689.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 3773461.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2242029.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize((64, 64)),\n",
    "        T.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = MNIST('mnist', train=True, transform=mnist_transforms, download=True)\n",
    "valid_dataset = MNIST('mnist', train=False, transform=mnist_transforms, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=4\n",
    "                          , pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f41409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:36.318079Z",
     "iopub.status.busy": "2024-11-18T14:57:36.317624Z",
     "iopub.status.idle": "2024-11-18T14:57:36.327744Z",
     "shell.execute_reply": "2024-11-18T14:57:36.326596Z"
    },
    "papermill": {
     "duration": 0.023265,
     "end_time": "2024-11-18T14:57:36.330399",
     "exception": false,
     "start_time": "2024-11-18T14:57:36.307134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for x, _ in tqdm(train_loader, desc='Train'):\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, x)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, _ in tqdm(loader, desc='Evaluation'):\n",
    "        x = x.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, x)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    total_loss /= len(loader)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70835af0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:36.350612Z",
     "iopub.status.busy": "2024-11-18T14:57:36.350114Z",
     "iopub.status.idle": "2024-11-18T14:57:36.361842Z",
     "shell.execute_reply": "2024-11-18T14:57:36.360614Z"
    },
    "papermill": {
     "duration": 0.024723,
     "end_time": "2024-11-18T14:57:36.364338",
     "exception": false,
     "start_time": "2024-11-18T14:57:36.339615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def visualize(model, xs):\n",
    "    model.eval()\n",
    "\n",
    "    to_pil = T.ToPILImage()\n",
    "\n",
    "    outputs = model(xs.to(device)).cpu()\n",
    "    \n",
    "    plt.figure(figsize=(20, 4))\n",
    "    \n",
    "    plt.imshow(\n",
    "        to_pil(\n",
    "            torch.cat(\n",
    "                (\n",
    "                    make_grid(xs[:10], nrow=10, pad_value=1),\n",
    "                    make_grid(outputs[:10], nrow=10, pad_value=1)\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def whole_train_valid_cycle(model, num_epochs, title):\n",
    "    train_loss_history, valid_loss_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model)\n",
    "        valid_loss = evaluate(model, valid_loader)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        valid_loss_history.append(valid_loss)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        visualize(model, next(iter(valid_loader))[0])\n",
    "\n",
    "        plot_stats(\n",
    "            train_loss_history, valid_loss_history,\n",
    "            title\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d00efe56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:36.384617Z",
     "iopub.status.busy": "2024-11-18T14:57:36.384143Z",
     "iopub.status.idle": "2024-11-18T14:57:36.403401Z",
     "shell.execute_reply": "2024-11-18T14:57:36.402304Z"
    },
    "papermill": {
     "duration": 0.032588,
     "end_time": "2024-11-18T14:57:36.406103",
     "exception": false,
     "start_time": "2024-11-18T14:57:36.373515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, upsample: bool = False):\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False, recompute_scale_factor=False)\n",
    "\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, in_channels: int, base_block: nn.Module = Block, base_size: int = 32, num_blocks: int = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.base_size = base_size\n",
    "\n",
    "        # encoder creation\n",
    "\n",
    "        encoder_blocks = []\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            encoder_blocks.append(\n",
    "                base_block(\n",
    "                    in_channels=base_size if i else in_channels,\n",
    "                    out_channels=base_size,\n",
    "                    kernel_size=3,\n",
    "                    stride=2\n",
    "                )\n",
    "            )\n",
    "\n",
    "        encoder_blocks.append(\n",
    "            base_block(\n",
    "                in_channels=base_size,\n",
    "                out_channels=base_size,\n",
    "                kernel_size=3\n",
    "            ).conv\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_blocks)  # N -> N // (2 ** num_blocks)\n",
    "\n",
    "        # decoder creation\n",
    "\n",
    "        decoder_blocks = []\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            decoder_blocks.append(\n",
    "                base_block(\n",
    "                    in_channels=base_size,\n",
    "                    out_channels=base_size,\n",
    "                    kernel_size=3,\n",
    "                    upsample=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "        decoder_blocks.append(\n",
    "            base_block(\n",
    "                in_channels=base_size,\n",
    "                out_channels=in_channels,\n",
    "                kernel_size=3\n",
    "            ).conv\n",
    "        )\n",
    "        decoder_blocks.append(nn.Sigmoid())\n",
    "\n",
    "        self.decoder = nn.Sequential(*decoder_blocks)  # N // (2 ** num_blocks) -> N\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [bs, base_size, N // (2 ** num_blocks), N // (2 ** num_blocks)]\n",
    "        x = self.decoder(x)\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "\n",
    "        return x\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def encode(self, x):\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "        return self.flatten(self.encoder(x)) # output.shape = [bs, base_size * N ** 2 / (2 ** num_blocks) ** 2]\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def decode(self, x):\n",
    "        # x.shape = [bs, base_size * N ** 2 / (2 ** num_blocks) ** 2]\n",
    "        latent_size = int(math.sqrt(x.shape[1] // self.base_size))\n",
    "\n",
    "        return self.decoder(x.view(-1, self.base_size, latent_size, latent_size))  # output.shape = [bs, in_channels, N, N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8bc8bd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:36.426327Z",
     "iopub.status.busy": "2024-11-18T14:57:36.425857Z",
     "iopub.status.idle": "2024-11-18T14:57:36.433087Z",
     "shell.execute_reply": "2024-11-18T14:57:36.431817Z"
    },
    "papermill": {
     "duration": 0.020302,
     "end_time": "2024-11-18T14:57:36.435461",
     "exception": false,
     "start_time": "2024-11-18T14:57:36.415159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "#print(torch.cuda.get_device_name())\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ac1613",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:36.456075Z",
     "iopub.status.busy": "2024-11-18T14:57:36.455215Z",
     "iopub.status.idle": "2024-11-18T14:57:36.467365Z",
     "shell.execute_reply": "2024-11-18T14:57:36.465966Z"
    },
    "papermill": {
     "duration": 0.025227,
     "end_time": "2024-11-18T14:57:36.469968",
     "exception": false,
     "start_time": "2024-11-18T14:57:36.444741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DenoisingBlock(Block):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, upsample: bool = False):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, upsample)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False, recompute_scale_factor=False)\n",
    "\n",
    "        if self.training:\n",
    "            x = x + torch.randn_like(x) * 0.05\n",
    "\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class DenoisingAutoEncoder(AutoEncoder):\n",
    "    def __init__(self, in_channels: int, base_block: nn.Module = DenoisingBlock, base_size: int = 32, num_blocks: int = 8):\n",
    "        super().__init__(in_channels, base_block, base_size, num_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            x = torch.clip(x + torch.randn_like(x) * 0.1, min=0, max=1)\n",
    "\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [bs, base_size, N // (2 ** num_blocks), N // (2 ** num_blocks)]\n",
    "        x = self.decoder(x)\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e4e675e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:36.491358Z",
     "iopub.status.busy": "2024-11-18T14:57:36.490928Z",
     "iopub.status.idle": "2024-11-18T14:57:36.537408Z",
     "shell.execute_reply": "2024-11-18T14:57:36.536363Z"
    },
    "papermill": {
     "duration": 0.060681,
     "end_time": "2024-11-18T14:57:36.540259",
     "exception": false,
     "start_time": "2024-11-18T14:57:36.479578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "de_model = DenoisingAutoEncoder(in_channels=1).to(device)\n",
    "\n",
    "optimizer = Adam(de_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c77ae41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:36.560364Z",
     "iopub.status.busy": "2024-11-18T14:57:36.559925Z",
     "iopub.status.idle": "2024-11-18T14:57:36.569095Z",
     "shell.execute_reply": "2024-11-18T14:57:36.567931Z"
    },
    "papermill": {
     "duration": 0.022074,
     "end_time": "2024-11-18T14:57:36.571568",
     "exception": false,
     "start_time": "2024-11-18T14:57:36.549494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def get_latent_labels(model, loader, count: int=None):\n",
    "    model.eval()\n",
    "    \n",
    "    total = 0\n",
    "    \n",
    "    latent = []\n",
    "    labels = []\n",
    "    \n",
    "    for x, y in loader:\n",
    "        z = model.encode(x.to(device)).cpu()\n",
    "        \n",
    "        latent.append(z)\n",
    "        labels.append(y)\n",
    "        \n",
    "        total += y.shape[0]\n",
    "        \n",
    "        if count is not None and total >= count:\n",
    "            break\n",
    "            \n",
    "    latent = torch.cat(latent)[:count].numpy()\n",
    "    labels = torch.cat(labels)[:count].numpy()\n",
    "    \n",
    "    return latent, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40f36a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:36.591649Z",
     "iopub.status.busy": "2024-11-18T14:57:36.591178Z",
     "iopub.status.idle": "2024-11-18T14:57:37.413353Z",
     "shell.execute_reply": "2024-11-18T14:57:37.411936Z"
    },
    "papermill": {
     "duration": 0.835775,
     "end_time": "2024-11-18T14:57:37.416524",
     "exception": false,
     "start_time": "2024-11-18T14:57:36.580749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, y_train = get_latent_labels(de_model, train_loader, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3301f67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:37.437329Z",
     "iopub.status.busy": "2024-11-18T14:57:37.436866Z",
     "iopub.status.idle": "2024-11-18T14:57:45.791920Z",
     "shell.execute_reply": "2024-11-18T14:57:45.790290Z"
    },
    "papermill": {
     "duration": 8.368841,
     "end_time": "2024-11-18T14:57:45.794759",
     "exception": false,
     "start_time": "2024-11-18T14:57:37.425918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier().fit(x_train, y_train)\n",
    "\n",
    "x_valid, y_valid = get_latent_labels(de_model, valid_loader, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee605d48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:45.816097Z",
     "iopub.status.busy": "2024-11-18T14:57:45.815190Z",
     "iopub.status.idle": "2024-11-18T14:57:46.006554Z",
     "shell.execute_reply": "2024-11-18T14:57:46.005429Z"
    },
    "papermill": {
     "duration": 0.205125,
     "end_time": "2024-11-18T14:57:46.009232",
     "exception": false,
     "start_time": "2024-11-18T14:57:45.804107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5279"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clf.predict(x_valid) == y_valid).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "233edc85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:57:46.029792Z",
     "iopub.status.busy": "2024-11-18T14:57:46.028801Z",
     "iopub.status.idle": "2024-11-18T14:57:46.036093Z",
     "shell.execute_reply": "2024-11-18T14:57:46.034918Z"
    },
    "papermill": {
     "duration": 0.020444,
     "end_time": "2024-11-18T14:57:46.038811",
     "exception": false,
     "start_time": "2024-11-18T14:57:46.018367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_embeddings(x_train, y_train, x_valid, y_valid):\n",
    "    assert x_train.shape[0] == 1000\n",
    "    assert x_valid.shape[0] == 10000\n",
    "    \n",
    "    assert y_train.shape[0] == 1000\n",
    "    assert y_valid.shape[0] == 10000\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            'x_train': x_train,\n",
    "            'y_train': y_train,\n",
    "            'x_valid': x_valid,\n",
    "            'y_valid': y_valid\n",
    "        },\n",
    "        'embeddings.pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d744e7",
   "metadata": {
    "papermill": {
     "duration": 0.00896,
     "end_time": "2024-11-18T14:57:46.057060",
     "exception": false,
     "start_time": "2024-11-18T14:57:46.048100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.739589,
   "end_time": "2024-11-18T14:57:47.490917",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-18T14:57:22.751328",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
