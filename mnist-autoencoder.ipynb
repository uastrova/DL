{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45c68d6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-19T16:38:27.001218Z",
     "iopub.status.busy": "2024-11-19T16:38:27.000077Z",
     "iopub.status.idle": "2024-11-19T16:38:33.061502Z",
     "shell.execute_reply": "2024-11-19T16:38:33.060358Z"
    },
    "papermill": {
     "duration": 6.070188,
     "end_time": "2024-11-19T16:38:33.063993",
     "exception": false,
     "start_time": "2024-11-19T16:38:26.993805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5832c360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:38:33.073736Z",
     "iopub.status.busy": "2024-11-19T16:38:33.073221Z",
     "iopub.status.idle": "2024-11-19T16:38:35.690819Z",
     "shell.execute_reply": "2024-11-19T16:38:35.689556Z"
    },
    "papermill": {
     "duration": 2.625524,
     "end_time": "2024-11-19T16:38:35.693748",
     "exception": false,
     "start_time": "2024-11-19T16:38:33.068224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 53543965.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 1531521.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 13621762.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1515434.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mnist_transforms = T.Compose(\n",
    "    [\n",
    "        T.Resize((64, 64)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.5,), (0.5,))\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = MNIST('mnist', train=True, transform=mnist_transforms, download=True)\n",
    "valid_dataset = MNIST('mnist', train=False, transform=mnist_transforms, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=4\n",
    "                          , pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bcdc596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:38:35.707103Z",
     "iopub.status.busy": "2024-11-19T16:38:35.706697Z",
     "iopub.status.idle": "2024-11-19T16:38:35.714549Z",
     "shell.execute_reply": "2024-11-19T16:38:35.713452Z"
    },
    "papermill": {
     "duration": 0.017548,
     "end_time": "2024-11-19T16:38:35.716932",
     "exception": false,
     "start_time": "2024-11-19T16:38:35.699384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "\n",
    "    for x, _ in tqdm(train_loader, desc='Train'):\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, x)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for x, _ in tqdm(loader, desc='Evaluation'):\n",
    "        x = x.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, x)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    total_loss /= len(loader)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef24333c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:38:35.730243Z",
     "iopub.status.busy": "2024-11-19T16:38:35.729751Z",
     "iopub.status.idle": "2024-11-19T16:38:35.738667Z",
     "shell.execute_reply": "2024-11-19T16:38:35.737361Z"
    },
    "papermill": {
     "duration": 0.018299,
     "end_time": "2024-11-19T16:38:35.740908",
     "exception": false,
     "start_time": "2024-11-19T16:38:35.722609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def visualize(model, xs):\n",
    "    model.eval()\n",
    "\n",
    "    to_pil = T.ToPILImage()\n",
    "\n",
    "    outputs = model(xs.to(device)).cpu()\n",
    "    \n",
    "    plt.figure(figsize=(20, 4))\n",
    "    \n",
    "    plt.imshow(\n",
    "        to_pil(\n",
    "            torch.cat(\n",
    "                (\n",
    "                    make_grid(xs[:10], nrow=10, pad_value=1),\n",
    "                    make_grid(outputs[:10], nrow=10, pad_value=1)\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def whole_train_valid_cycle(model, num_epochs, title):\n",
    "    train_loss_history, valid_loss_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model)\n",
    "        valid_loss = evaluate(model, valid_loader)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        valid_loss_history.append(valid_loss)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        visualize(model, next(iter(valid_loader))[0])\n",
    "\n",
    "        plot_stats(\n",
    "            train_loss_history, valid_loss_history,\n",
    "            title\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "911b659d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:38:35.753097Z",
     "iopub.status.busy": "2024-11-19T16:38:35.752749Z",
     "iopub.status.idle": "2024-11-19T16:38:35.768506Z",
     "shell.execute_reply": "2024-11-19T16:38:35.767638Z"
    },
    "papermill": {
     "duration": 0.024403,
     "end_time": "2024-11-19T16:38:35.770643",
     "exception": false,
     "start_time": "2024-11-19T16:38:35.746240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, upsample: bool = False):\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.norm = nn.BatchNorm2d(out_channels)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False, recompute_scale_factor=False)\n",
    "\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, in_channels: int, base_block: nn.Module = Block, base_size: int = 32, num_blocks: int = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.base_size = base_size\n",
    "\n",
    "        # encoder creation\n",
    "\n",
    "        encoder_blocks = []\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            encoder_blocks.append(\n",
    "                base_block(\n",
    "                    in_channels=base_size if i else in_channels,\n",
    "                    out_channels=base_size,\n",
    "                    kernel_size=3,\n",
    "                    stride=2\n",
    "                )\n",
    "            )\n",
    "\n",
    "        encoder_blocks.append(\n",
    "            base_block(\n",
    "                in_channels=base_size,\n",
    "                out_channels=base_size,\n",
    "                kernel_size=3\n",
    "            ).conv\n",
    "        )\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_blocks)  # N -> N // (2 ** num_blocks)\n",
    "\n",
    "        # decoder creation\n",
    "\n",
    "        decoder_blocks = []\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            decoder_blocks.append(\n",
    "                base_block(\n",
    "                    in_channels=base_size,\n",
    "                    out_channels=base_size,\n",
    "                    kernel_size=3,\n",
    "                    upsample=True\n",
    "                )\n",
    "            )\n",
    "\n",
    "        decoder_blocks.append(\n",
    "            base_block(\n",
    "                in_channels=base_size,\n",
    "                out_channels=in_channels,\n",
    "                kernel_size=3\n",
    "            ).conv\n",
    "        )\n",
    "        decoder_blocks.append(nn.Sigmoid())\n",
    "\n",
    "        self.decoder = nn.Sequential(*decoder_blocks)  # N // (2 ** num_blocks) -> N\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [bs, base_size, N // (2 ** num_blocks), N // (2 ** num_blocks)]\n",
    "        x = self.decoder(x)\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "\n",
    "        return x\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def encode(self, x):\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "        return self.flatten(self.encoder(x)) # output.shape = [bs, base_size * N ** 2 / (2 ** num_blocks) ** 2]\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def decode(self, x):\n",
    "        # x.shape = [bs, base_size * N ** 2 / (2 ** num_blocks) ** 2]\n",
    "        latent_size = int(math.sqrt(x.shape[1] // self.base_size))\n",
    "\n",
    "        return self.decoder(x.view(-1, self.base_size, latent_size, latent_size))  # output.shape = [bs, in_channels, N, N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63a4a196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:38:35.783220Z",
     "iopub.status.busy": "2024-11-19T16:38:35.782225Z",
     "iopub.status.idle": "2024-11-19T16:38:35.788660Z",
     "shell.execute_reply": "2024-11-19T16:38:35.787599Z"
    },
    "papermill": {
     "duration": 0.015092,
     "end_time": "2024-11-19T16:38:35.790971",
     "exception": false,
     "start_time": "2024-11-19T16:38:35.775879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "#print(torch.cuda.get_device_name())\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec0d757e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:38:35.803341Z",
     "iopub.status.busy": "2024-11-19T16:38:35.802909Z",
     "iopub.status.idle": "2024-11-19T16:38:35.812065Z",
     "shell.execute_reply": "2024-11-19T16:38:35.810905Z"
    },
    "papermill": {
     "duration": 0.017805,
     "end_time": "2024-11-19T16:38:35.814129",
     "exception": false,
     "start_time": "2024-11-19T16:38:35.796324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DenoisingBlock(Block):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, upsample: bool = False):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, upsample)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.upsample:\n",
    "            x = nn.functional.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False, recompute_scale_factor=False)\n",
    "\n",
    "        if self.training:\n",
    "            x = x + torch.randn_like(x) * 0.05\n",
    "\n",
    "        return self.act(self.norm(self.conv(x)))\n",
    "\n",
    "\n",
    "class DenoisingAutoEncoder(AutoEncoder):\n",
    "    def __init__(self, in_channels: int, base_block: nn.Module = DenoisingBlock, base_size: int = 32, num_blocks: int = 8):\n",
    "        super().__init__(in_channels, base_block, base_size, num_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            x = torch.clip(x + torch.randn_like(x) * 0.1, min=0, max=1)\n",
    "\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "        x = self.encoder(x)\n",
    "        # x.shape = [bs, base_size, N // (2 ** num_blocks), N // (2 ** num_blocks)]\n",
    "        x = self.decoder(x)\n",
    "        # x.shape = [bs, in_channels, N, N]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c27af1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:38:35.826548Z",
     "iopub.status.busy": "2024-11-19T16:38:35.826174Z",
     "iopub.status.idle": "2024-11-19T16:54:02.499954Z",
     "shell.execute_reply": "2024-11-19T16:54:02.498378Z"
    },
    "papermill": {
     "duration": 926.688466,
     "end_time": "2024-11-19T16:54:02.508085",
     "exception": false,
     "start_time": "2024-11-19T16:38:35.819619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Loss: 0.8881\n",
      "Epoch [2/6], Loss: 0.8290\n",
      "Epoch [3/6], Loss: 0.8252\n",
      "Epoch [4/6], Loss: 0.8234\n",
      "Epoch [5/6], Loss: 0.8224\n",
      "Epoch [6/6], Loss: 0.8216\n"
     ]
    }
   ],
   "source": [
    "model = DenoisingAutoEncoder(\n",
    "    in_channels=1,\n",
    "    base_block=DenoisingBlock,  # Используем denoising-блок\n",
    "    base_size=8,\n",
    "    num_blocks=4  # Соответствует архитектуре\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()  # Или BCELoss, если требуется\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs=6\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, _ in train_loader:\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f04a65b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:54:02.521183Z",
     "iopub.status.busy": "2024-11-19T16:54:02.520726Z",
     "iopub.status.idle": "2024-11-19T16:54:02.529497Z",
     "shell.execute_reply": "2024-11-19T16:54:02.528224Z"
    },
    "papermill": {
     "duration": 0.018216,
     "end_time": "2024-11-19T16:54:02.531744",
     "exception": false,
     "start_time": "2024-11-19T16:54:02.513528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def get_latent_labels(model, loader, count: int=None):\n",
    "    model.eval()\n",
    "    \n",
    "    total = 0\n",
    "    \n",
    "    latent = []\n",
    "    labels = []\n",
    "    \n",
    "    for x, y in loader:\n",
    "        z = model.encode(x.to(device)).cpu()\n",
    "        \n",
    "        latent.append(z)\n",
    "        labels.append(y)\n",
    "        \n",
    "        total += y.shape[0]\n",
    "        \n",
    "        if count is not None and total >= count:\n",
    "            break\n",
    "            \n",
    "    latent = torch.cat(latent)[:count].numpy()\n",
    "    labels = torch.cat(labels)[:count].numpy()\n",
    "    \n",
    "    return latent, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f258a2fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:54:02.545451Z",
     "iopub.status.busy": "2024-11-19T16:54:02.545042Z",
     "iopub.status.idle": "2024-11-19T16:54:03.003933Z",
     "shell.execute_reply": "2024-11-19T16:54:03.002561Z"
    },
    "papermill": {
     "duration": 0.469044,
     "end_time": "2024-11-19T16:54:03.006483",
     "exception": false,
     "start_time": "2024-11-19T16:54:02.537439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, y_train = get_latent_labels(model, train_loader, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f5a0dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:54:03.020243Z",
     "iopub.status.busy": "2024-11-19T16:54:03.019668Z",
     "iopub.status.idle": "2024-11-19T16:54:08.627204Z",
     "shell.execute_reply": "2024-11-19T16:54:08.625522Z"
    },
    "papermill": {
     "duration": 5.617492,
     "end_time": "2024-11-19T16:54:08.629785",
     "exception": false,
     "start_time": "2024-11-19T16:54:03.012293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier().fit(x_train, y_train)\n",
    "\n",
    "x_valid, y_valid = get_latent_labels(model, valid_loader, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "223c963f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:54:08.643754Z",
     "iopub.status.busy": "2024-11-19T16:54:08.642850Z",
     "iopub.status.idle": "2024-11-19T16:54:08.826728Z",
     "shell.execute_reply": "2024-11-19T16:54:08.825538Z"
    },
    "papermill": {
     "duration": 0.193702,
     "end_time": "2024-11-19T16:54:08.829191",
     "exception": false,
     "start_time": "2024-11-19T16:54:08.635489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(clf.predict(x_valid) == y_valid).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50c971d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:54:08.842671Z",
     "iopub.status.busy": "2024-11-19T16:54:08.842253Z",
     "iopub.status.idle": "2024-11-19T16:54:08.848960Z",
     "shell.execute_reply": "2024-11-19T16:54:08.847892Z"
    },
    "papermill": {
     "duration": 0.016056,
     "end_time": "2024-11-19T16:54:08.851211",
     "exception": false,
     "start_time": "2024-11-19T16:54:08.835155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_embeddings(x_train, y_train, x_valid, y_valid):\n",
    "    assert x_train.shape[0] == 1000\n",
    "    assert x_valid.shape[0] == 10000\n",
    "    \n",
    "    assert y_train.shape[0] == 1000\n",
    "    assert y_valid.shape[0] == 10000\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            'x_train': x_train,\n",
    "            'y_train': y_train,\n",
    "            'x_valid': x_valid,\n",
    "            'y_valid': y_valid\n",
    "        },\n",
    "        'embeddings.pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "300dd7b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-19T16:54:08.864525Z",
     "iopub.status.busy": "2024-11-19T16:54:08.864125Z",
     "iopub.status.idle": "2024-11-19T16:54:08.948351Z",
     "shell.execute_reply": "2024-11-19T16:54:08.947162Z"
    },
    "papermill": {
     "duration": 0.09404,
     "end_time": "2024-11-19T16:54:08.951087",
     "exception": false,
     "start_time": "2024-11-19T16:54:08.857047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_embeddings(x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d5ff7",
   "metadata": {
    "papermill": {
     "duration": 0.005733,
     "end_time": "2024-11-19T16:54:08.962753",
     "exception": false,
     "start_time": "2024-11-19T16:54:08.957020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 947.34257,
   "end_time": "2024-11-19T16:54:10.496071",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-19T16:38:23.153501",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
